{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd52306-9868-4ff1-a001-f51802df728e",
   "metadata": {},
   "source": [
    "### 1\n",
    "The nonplanning method looks particularly poor in Figure 8.3 because it is\n",
    "a one-step method; a method using multi-step bootstrapping would do better. Do you\n",
    "think one of the multi-step bootstrapping methods from Chapter 7 could do as well as\n",
    "the Dyna method? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc855f8-e0f0-4089-8cf1-4dab9bf71cef",
   "metadata": {},
   "source": [
    "I belive that both sarsa and expected sarsa could replace this method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70741e-07d9-4c3b-8e41-99baf377abe2",
   "metadata": {},
   "source": [
    "### 2\n",
    "Why did the Dyna agent with exploration bonus, Dyna-Q+, perform\n",
    "better in the first phase as well as in the second phase of the blocking and shortcut\n",
    "experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d127ff4-348c-471d-b898-dce7d649e676",
   "metadata": {},
   "source": [
    "It's because of the exploration is found the optimal path quicker, and when we opened \n",
    "the second path is actually found the other better way after being forced to approach it\n",
    "from time to time and eventually updating it's values to better math current dynamics of \n",
    "the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c1edd-fc5d-431b-997c-04b8c940f7d6",
   "metadata": {},
   "source": [
    "### 3\n",
    "Careful inspection of Figure 8.5 reveals that the difference between Dyna-Q+\n",
    "and Dyna-Q narrowed slightly over the first part of the experiment. What is the reason\n",
    "for this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0958871-c673-4229-bdf3-3aea7fc2c0a9",
   "metadata": {},
   "source": [
    "It's because Dyna-Q+ kept exploring still not opened path while normal Dyna just stick to\n",
    "it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86838f-ad7a-4a73-96e3-12b9c933b4e3",
   "metadata": {},
   "source": [
    "### 4 (programming)\n",
    "The exploration bonus described above actually changes\n",
    "the estimated values of states and actions. Is this necessary? Suppose the bonus $\\kappa \\sqrt{\\tau}$ \n",
    "was used not in updates, but solely in action selection.\n",
    "That is, suppose the action\n",
    "selected was always that for which $Q(S_t , a) + \\kappa \\sqrt{\\tau(S_t , a)}$ was maximal. Carry out a\n",
    "gridworld experiment that tests and illustrates the strengths and weaknesses of this\n",
    "alternate approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3323e-ae07-4b05-a5fa-ab43c19dc8a9",
   "metadata": {},
   "source": [
    "### 5\n",
    "How might the tabular Dyna-Q algorithm shown on page 164 be modified\n",
    "to handle stochastic environments? How might this modification perform poorly on\n",
    "changing environments such as considered in this section? How could the algorithm be\n",
    "modified to handle stochastic environments and changing environments?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d59b9-6fad-4fdf-83e3-91fe373e9a26",
   "metadata": {},
   "source": [
    "it's model could return arrays containing tuples of reward and state with probabilities\n",
    "of them occuring, then it could update value functions for all of these tuples but\n",
    "change $\\alpha$ to $\\alpha \\cdot p$, where $p$ is this probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99e77e-114d-4872-a88e-917cab6873d4",
   "metadata": {},
   "source": [
    "### 6\n",
    "The analysis above (8.5, page 172-174) assumed that all of the $b$ possible next states \n",
    "were\n",
    "equally likely to occur. Suppose instead that the distribution was highly skewed, that\n",
    "some of the b states were much more likely to occur than most. Would this strengthen or\n",
    "weaken the case for sample updates over expected updates? Support your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912f888-a1a7-45d1-be41-ea60aacd2489",
   "metadata": {},
   "source": [
    "It would probably lessen the difference between the two since we will have better \n",
    "estimates for states that we are likely to occur, so we wont waste computational time\n",
    "for cases which we may never even encounter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79371b3-44f2-4039-86e2-91deb85627d8",
   "metadata": {},
   "source": [
    "### 7\n",
    "Some of the graphs in Figure 8.8 seem to be scalloped in their early portions,\n",
    "particularly the upper graph for $b = 1$ and the uniform distribution. Why do you think\n",
    "this is? What aspects of the data shown support your hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa41421-ef7b-4e29-a7a6-53fa0c449b02",
   "metadata": {},
   "source": [
    "### 8 (programming)\n",
    "Replicate the experiment whose results are shown in the\n",
    "lower part of Figure 8.8, then try the same experiment but with $b = 3$. Discuss the\n",
    "meaning of your results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
